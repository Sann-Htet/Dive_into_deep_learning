{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cabb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from d2l import torch as d2l\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import matplotlib.pyplot as plt\n",
    "from syne_tune import StoppingCriterion, Tuner\n",
    "from syne_tune.backend.python_backend import PythonBackend\n",
    "from syne_tune.config_space import loguniform, randint\n",
    "from syne_tune.experiments import load_experiment\n",
    "from syne_tune.optimizer.baselines import ASHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b49107",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a439bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpo_objective_lenet_synetune(learning_rate, batch_size, max_epochs):\n",
    "    from syne_tune import Reporter\n",
    "    from d2l import torch as d2l\n",
    "\n",
    "    model = d2l.LeNet(lr=learning_rate, num_classes=10)\n",
    "    trainer = d2l.HPOTrainer(max_epochs=1, num_gpus=1)\n",
    "    data = d2l.FashionMNIST(batch_size=batch_size)\n",
    "    model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
    "    report = Reporter()\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        if epoch == 1:\n",
    "            # Initialize the state of Trainer\n",
    "            trainer.fit(model=model, data=data)\n",
    "        else:\n",
    "            trainer.fit_epoch()\n",
    "        validation_error = trainer.validation_error().cpu().detach().numpy()\n",
    "        report(epoch=epoch, validation_error=float(validation_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_number_of_epochs = 2\n",
    "max_number_of_epochs = 10\n",
    "eta = 2\n",
    "\n",
    "config_space = {\n",
    "    \"learning_rate\": loguniform(1e-2, 1),\n",
    "    \"batch_size\": randint(32, 256),\n",
    "    \"max_epochs\": max_number_of_epochs,\n",
    "}\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1234680",
   "metadata": {},
   "source": [
    "## Asynchronous Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba7aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 2 # Needs to be <= the number of available GPUs\n",
    "max_wallclock_time = 12 * 60 # 12 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"min\"\n",
    "metric = \"validation_error\"\n",
    "resource_attr = \"epoch\"\n",
    "\n",
    "scheduler = ASHA(\n",
    "    config_space,\n",
    "    metric=metric,\n",
    "    mode=mode,\n",
    "    points_to_evaluate=[initial_config],\n",
    "    max_resource_attr=\"max_epochs\",\n",
    "    resource_attr=resource_attr,\n",
    "    grace_period=min_number_of_epochs,\n",
    "    reduction_factor=eta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda71d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_backend = PythonBackend(\n",
    "    tune_function=hpo_objective_lenet_synetune,\n",
    "    config_space=config_space,\n",
    ")\n",
    "\n",
    "stop_criterion = StoppingCriterion(max_wallclock_time=max_wallclock_time)\n",
    "tuner = Tuner(\n",
    "    trial_backend=trial_backend,\n",
    "    scheduler=scheduler,\n",
    "    stop_criterion=stop_criterion,\n",
    "    n_workers=n_workers,\n",
    "    print_update_interval=int(max_wallclock_time * 0.6),\n",
    ")\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c83d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.set_figsize()\n",
    "e = load_experiment(tuner.name)\n",
    "e.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f088a82",
   "metadata": {},
   "source": [
    "## Visualize the Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e50ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.set_figsize([6, 2.5])\n",
    "results = e.results\n",
    "for trial_id in results.trial_id.unique():\n",
    "    df = results[results[\"trial_id\"] == trial_id]\n",
    "    d2l.plt.plot(\n",
    "        df[\"st_tuner_time\"],\n",
    "        df[\"validation_error\"],\n",
    "        marker=\"o\"\n",
    "    )\n",
    "d2l.plt.xlabel(\"wall-clock time\")\n",
    "d2l.plt.ylabel(\"objective function\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
