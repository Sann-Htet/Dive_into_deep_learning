{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd528cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa36d8",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b8a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNScratch(d2l.Module):   #@save\n",
    "    \"\"\"The RNN model implemented from scratch.\"\"\"\n",
    "    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.W_xh = nn.Parameter(\n",
    "            torch.randn(num_inputs, num_hiddens) * sigma\n",
    "        )\n",
    "        self.W_hh = nn.Parameter(\n",
    "            torch.randn(num_hiddens, num_hiddens) * sigma\n",
    "        )\n",
    "        self.b_h = nn.Parameter(torch.zeros(num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de237ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(RNNScratch)   #@save\n",
    "def forward(self, inputs, state=None):\n",
    "    if state is None:\n",
    "        # Initial state with shape: (batch_size, num_hiddens)\n",
    "        state = torch.zeros(\n",
    "            (inputs.shape[1], self.num_hiddens),\n",
    "            device=inputs.device\n",
    "        )\n",
    "    else:\n",
    "        state, = state\n",
    "    outputs = []\n",
    "    for X in inputs:    # Shape of inputs: (num_steps, batch_size, num_inputs)\n",
    "        state = torch.tanh(\n",
    "            torch.matmul(X, self.W_xh) + torch.matmul(state, self.W_hh) + self.b_h\n",
    "        )\n",
    "        outputs.append(state)\n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce35a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_inputs, num_hiddens, num_steps = 2, 16, 32, 100\n",
    "rnn = RNNScratch(num_inputs, num_hiddens)\n",
    "X = torch.ones((num_steps, batch_size, num_inputs))\n",
    "outputs, state = rnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9648c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_len(a, n):    #@save\n",
    "    \"\"\"Check the length of a list.\"\"\"\n",
    "    assert len(a) == n, f'list\\'s length {len(a)} != expected length {n}'\n",
    "\n",
    "def check_shape(a, shape):  #@save\n",
    "    \"\"\"Check the shape of a tensor.\"\"\"\n",
    "    assert a.shape == shape, \\\n",
    "        f'tensor\\'s shape {a.shape} != expected shape {shape}'\n",
    "    \n",
    "check_len(outputs, num_steps)\n",
    "check_shape(outputs[0], (batch_size, num_hiddens))\n",
    "check_shape(state, (batch_size, num_hiddens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b4618",
   "metadata": {},
   "source": [
    "## RNN-Based Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e15889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLMScratch(d2l.Classifier): #@save\n",
    "    \"\"\"The RNN-based language model implemented from scratch.\"\"\"\n",
    "    def __init__(self, rnn, vocab_size, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.W_hq = nn.Parameter(\n",
    "            torch.randn(\n",
    "                self.rnn.num_hiddens, self.vocab_size\n",
    "            ) * self.rnn.sigma\n",
    "        )\n",
    "        self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=True)\n",
    "        return l\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('ppl', torch.exp(l), train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91327e7d",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0498986a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor([0, 2]), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe954e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(RNNLMScratch) #@save\n",
    "def one_hot(self, X):\n",
    "    # Output shape: (num_steps, batch_size, vocab_size)\n",
    "    return F.one_hot(X.T, self.vocab_size).type(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ace39",
   "metadata": {},
   "source": [
    "### Transforming RNN Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3115533",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(RNNLMScratch) #@save\n",
    "def output_layer(self, rnn_outputs):\n",
    "    outputs = [torch.matmul(H, self.W_hq) + self.b_q for H in rnn_outputs]\n",
    "    return torch.stack(outputs, 1)\n",
    "\n",
    "@d2l.add_to_class(RNNLMScratch) #@save\n",
    "def forward(self, X, state=None):\n",
    "    embs = self.one_hot(X)\n",
    "    rnn_outputs, _ = self.rnn(embs, state)\n",
    "    return self.output_layer(rnn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70c9488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNLMScratch(rnn, num_inputs)\n",
    "outputs = model(torch.ones((batch_size, num_steps), dtype=torch.int64))\n",
    "check_shape(outputs, (batch_size, num_steps, num_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39525a5c",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de5caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
